name: Scraping con Selenium

on:
  schedule:
    - cron: '0 1 * * *'  # todos los d√≠as a las 1 AM UTC
  workflow_dispatch:     # permite ejecutarlo manualmente

jobs:
  ejecutar:
    runs-on: ubuntu-latest
    environment: python_s3 

    steps:
      - name: Clonar repositorio
        uses: actions/checkout@v3

      - name: Instalar Google Chrome compatible
        run: |
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo apt install -y ./google-chrome-stable_current_amd64.deb

      - name: Instalar dependencias de Python
        run: |
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Verificar variables de entorno (debug)
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          BUCKET_NAME: ${{ secrets.BUCKET_NAME }}
        run: |
          echo "AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}"
          echo "AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}"
          echo "BUCKET_NAME=${BUCKET_NAME}"

      - name: Ejecutar script
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          BUCKET_NAME: ${{ secrets.BUCKET_NAME }}
        run: |
          python3 -u genera_informacion.py
      
      - name: Subir HTML generado
        uses: actions/upload-artifact@v3
        with:
          name: html-debug
          path: debug_facebook.html
